---
title: 'Weekly Exercises #6'
author: "Put your name here"
output: 
  html_document:
    keep_md: TRUE
    toc: TRUE
    toc_float: TRUE
    df_print: paged
    code_download: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, error=TRUE, message=FALSE, warning=FALSE)
```

```{r libraries}
library(tidyverse)     # for data cleaning and plotting
library(gardenR)       # for Lisa's garden data
library(lubridate)     # for date manipulation
library(openintro)     # for the abbr2state() function
library(palmerpenguins)# for Palmer penguin data
library(maps)          # for map data
library(ggmap)         # for mapping points on maps
library(gplots)        # for col2hex() function
library(RColorBrewer)  # for color palettes
library(sf)            # for working with spatial data
library(leaflet)       # for highly customizable mapping
library(ggthemes)      # for more themes (including theme_map())
library(plotly)        # for the ggplotly() - basic interactivity
library(gganimate)     # for adding animation layers to ggplots
library(gifski)        # for creating the gif (don't need to load this library every time,but need it installed)
library(transformr)    # for "tweening" (gganimate)
library(patchwork)     # for nicely combining ggplot2 graphs  
library(rvest)         # for scraping data
library(robotstxt)     # for checking if you can scrape data
library(gt)            # for creating nice tables

theme_set(theme_minimal())
```

```{r data}
# Lisa's garden data
data("garden_harvest")

#COVID-19 data from the New York Times
covid19 <- read_csv("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv")

```

## Put your homework on GitHub!

Go [here](https://github.com/llendway/github_for_collaboration/blob/master/github_for_collaboration.md) or to previous homework to remind yourself how to get set up. 

Once your repository is created, you should always open your **project** rather than just opening an .Rmd file. You can do that by either clicking on the .Rproj file in your repository folder on your computer. Or, by going to the upper right hand corner in R Studio and clicking the arrow next to where it says Project: (None). You should see your project come up in that list if you've used it recently. You could also go to File --> Open Project and navigate to your .Rproj file. 

## Instructions

* Put your name at the top of the document. 

* **For ALL graphs, you should include appropriate labels.** 

* Feel free to change the default theme, which I currently have set to `theme_minimal()`. 

* Use good coding practice. Read the short sections on good code with [pipes](https://style.tidyverse.org/pipes.html) and [ggplot2](https://style.tidyverse.org/ggplot2.html). **This is part of your grade!**

* **NEW!!** With animated graphs, add `eval=FALSE` to the code chunk that creates the animation and saves it using `anim_save()`. Add another code chunk to reread the gif back into the file. See the [tutorial](https://animation-and-interactivity-in-r.netlify.app/) for help. 

* When you are finished with ALL the exercises, uncomment the options at the top so your document looks nicer. Don't do it before then, or else you might miss some important warnings and messages.


## Warm-up exercises from tutorial

1. Read in the fake garden harvest data. Find the data [here](https://github.com/llendway/scraping_etc/blob/main/2020_harvest.csv) and click on the `Raw` button to get a direct link to the data. After reading in the data, do one of the quick checks mentioned in the tutorial.
  
```{r}
library('readr')
X2020_harvest <- read_csv("https://raw.githubusercontent.com/llendway/scraping_etc/main/2020_harvest.csv", 
    col_types = cols(weight = col_number()), 
    na = "MISSING", skip = 2)%>%
  select(-...1)
X2020_harvest
```
  
```{r}
X2020_harvest %>% 
  mutate(across(where(is.character), as.factor)) %>% 
  summary()
```
  
  
  
  
2. Read in this [data](https://www.kaggle.com/heeraldedhia/groceries-dataset) from the kaggle website. You will need to download the data first. Save it to your project/repo folder. Do some quick checks of the data to assure it has been read in appropriately.
```{r}
Groceries_dataset <- read_csv("Groceries_dataset.csv")
Groceries_dataset %>%
  mutate(across(where(is.character), as.factor)) %>% 
  summary()
```



3. Create a table using `gt` with data from your project or from the `garden_harvest` data if your project data aren't ready. Use at least 3 `gt()` functions.

```{r}

Employee<-read.csv('Employee.csv')
Employee %>%
  select(Attrition,Department,DistanceFromHome,Gender,JobLevel,JobSatisfaction,MonthlyIncome) %>%
  gt() %>%
  
  tab_header(
    title = "Employee Attrition",
    subtitle = md("Dataset from **Kaggle**")
  ) %>%
  
  tab_footnote(
    footnote = " This is a fictional dataset created by IBM data scientists",
    locations = cells_title()
  ) %>%
  
  fmt_currency(columns=c(MonthlyIncome),
               currency = "USD")
```



4. CHALLENGE (not graded): Write code to replicate the table shown below (open the .html file to see it) created from the `garden_harvest` data as best as you can. When you get to coloring the cells, I used the following line of code for the `colors` argument:


  
5. Use `patchwork` operators and functions to combine at least two graphs using your project data or `garden_harvest` data if your project data aren't read.
  
  
```{r}
a<- Employee %>% 
  ggplot(aes(x = MonthlyIncome, color = Gender)) +
  geom_boxplot(alpha = 0.2 ) +
  geom_vline(aes(xintercept = mean(MonthlyIncome)), color = "#4F2C1DFF", size = 1) +
  facet_wrap(vars (Department)) + 
  scale_color_manual(values = c("Female" = "#E95C20FF",
                                "Male"="#006747FF")) + 
  labs(title = "Monthly Income Distributions by department", 
       subtitle = "Histogram Plot",
       x = NULL,
       y = NULL)


b<-Employee %>%
  group_by(Department,TotalWorkingYears,Attrition) %>%
  summarize(`Average income` = mean(MonthlyIncome)) %>%
  ggplot(aes(x=TotalWorkingYears)) +
  geom_point(size=1,
            aes( y=`Average income`,
            color=Attrition))+
  geom_smooth(aes(y=`Average income`,
             color=Attrition),
             se = FALSE,n=30,size=0.7)+
  facet_wrap(~Department)+
  theme_classic()+
  labs(x='Total working years')

library(survival)
es<-Employee%>%
  mutate(attrition=ifelse(Attrition=="YES",0,1))
km<-survfit(Surv(YearsAtCompany,attrition)~1,data=es)
c<-plot(km,conf.int=TRUE,main="Kaplan-Meier Survival curve of Employee",xlab="Years at company",ylab="1 - P(Attrition)")

a/b + 
  plot_annotation(title = "Project Graphs") 
```
  
  
  
  
  
## Webscraping exercise (also from tutorial)

Use the data from the [Macalester Registrar's Fall 2017 Class Schedule](https://www.macalester.edu/registrar/schedules/2017fall/class-schedule/#crs10008) to complete all these exercises.

6. Find the correct selectors for the following fields. Make sure that each matches 762 results:

  * Course Number
  * Course Name
  * Day
  * Time
  * Room
  * Instructor
  * Avail. / Max
  * General Education Requirements (make sure you only match 762; beware of the Mac copyright banner at the bottom of the page!)
  * Description

Then, put all this information into one dataset (tibble or data.frame) Do not include any extraneous information like "Instructor: ".
  
```{r}
fall2017 <- read_html("https://www.macalester.edu/registrar/schedules/2017fall/class-schedule/#crs10008")
```

```{r}
# Retrieve and inspect course numbers
course_nums <- 
  fall2017 %>%
  html_elements(".class-schedule-course-number") %>%
  html_text2()


# Retrieve and inspect course names
course_names <- 
  fall2017 %>%
  html_elements(".class-schedule-course-title") %>%
  html_text2()

course_days <- fall2017 %>%
  html_elements(".class-schedule-course-title+ .class-schedule-label") %>%
  html_text2() %>%
  str_sub(start = 7)

course_time <- fall2017 %>%
  html_elements(".class-schedule-label:nth-child(4)
") %>%
  html_text2() %>%
  str_sub(start =7)

course_room <- fall2017 %>%
  html_elements(".class-schedule-label:nth-child(5)
") %>%
  html_text2() %>%
  str_sub(start=7)

course_instructor <-course_days <- fall2017 %>%
  html_elements(".class-schedule-label:nth-child(6)
") %>%
  html_text2() %>%
  str_sub(start = 13)

course_avail <-course_days <- fall2017 %>%
  html_elements(".class-schedule-label:nth-child(7)
") %>%
  html_text2() %>%
   str_sub(start = 14)

course_GenEd <-course_days <- fall2017 %>%
  html_elements("#content p:nth-child(2)
") %>%
  html_text2() %>%
  str_sub(start = 35)

course_description <-course_days <- fall2017 %>%
  html_elements(".collapsed p:nth-child(1)
") %>%
  html_text2() %>%
  str_sub(start=3)
```

```{r}
#table
fallcourse2017<-tibble(number=course_nums, 
                      name=course_names,
                      day=course_days,
                      time=course_time,
                      room=course_room,
                      instructor=course_instructor,
                      `avail./max.`=course_avail,
                      `general education requirement` = course_GenEd,
                      description=course_description
                      )
head(fallcourse2017)
```


7. Create a graph that shows the number of sections offered per department. Hint: The department is a substring of the course number - there are `str_XXX()` functions that can help. Yes, COMP and MATH are the same department, but for this exercise you can just show the results by four letter department code, e.g., with COMP and MATH separate.

```{r}
fallcourse2017 %>%
  separate(number,
           into = c("department","section"),
           remove = FALSE) %>%
  mutate(department=fct_infreq(department))%>%
  count(department)%>%
  ggplot(aes(y=department,x=n)) +
  geom_col() +
  labs(title="Number of sections offered by departments",
       x="",y="")


```


8. Analyze the typical length of course names by department. To do so, create a new data table based on your courses data table, with the following changes:
  
  * New columns for the length of the title of a course and the length of the description of the course. Hint: `str_length`.  
  * Remove departments that have fewer than 10 sections of courses. To do so, group by department, then remove observations in groups with fewer than 10 sections (Hint: use filter with n()). Then `ungroup()` the data.  
  * Create a visualization of the differences across groups in lengths of course names or course descriptions. Think carefully about the visualization you should be using!


```{r}
depart1 <- fallcourse2017 %>%
  separate(number,
           into = c("department","section"),
           remove = FALSE) %>%
  group_by(department) %>%
  summarize(secnum = n()) %>%
  ungroup() %>% 
  filter(secnum >9)
```


```{r}
fallcourse2017 %>%
  mutate(desclen = str_length(description)) %>%
  separate(number,
           into = c("department","section"),
           remove = FALSE) %>%
  filter(department %in% depart1$department) %>%

  ggplot(aes(y=fct_reorder(department,desclen),
             x=desclen)) +
  geom_boxplot()+
  labs(title="Distribution of course descrption length by department",
       x="",y="")
```

Github link
https://github.com/GeV-123/exercise-06.git
  

**DID YOU REMEMBER TO UNCOMMENT THE OPTIONS AT THE TOP?**
